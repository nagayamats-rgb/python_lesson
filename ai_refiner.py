"""
ğŸŒ¸ KOTOHA ENGINE v1.6 - ai_refiner.py
---------------------------------------------
ç¬¬ä¸‰ãƒ¬ã‚¤ãƒ¤ãƒ¼ï¼šAIç”Ÿæˆå±¤
ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‡ºåŠ› (output_templates_*.csv) ã‚’èª­ã¿è¾¼ã¿ã€
OpenAI APIã‚’ç”¨ã„ã¦è‡ªç„¶ã§é­…åŠ›çš„ãªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã¨ALTæ–‡ã‚’ç”Ÿæˆã™ã‚‹ã€‚

ç›®çš„ï¼š
- KOTOHA ENGINE ã®ã€Œè·äººå‹AIã€æ®µéšã¸ã®é€²åŒ–
- å„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ–‡ã‚’ãƒªãƒ©ã‚¤ãƒˆã—ã€æ„Ÿæ€§ãƒ»è‡ªç„¶æ€§ãƒ»SEOã‚’å¼·åŒ–
- APIã‚­ãƒ¼ã‚„å‡ºåŠ›è¨­å®šã¯ .env / kotoha_config.json / modules/ai_refiner.json ã‹ã‚‰è‡ªå‹•å‚ç…§
"""

import os
import re
import json
import glob
import logging
import pandas as pd
from dotenv import load_dotenv
from datetime import datetime
import openai

# -----------------------------------
# ğŸŒ¸ ãƒ­ã‚¬ãƒ¼è¨­å®š
# -----------------------------------
logger = logging.getLogger("KOTOHA_ENGINE_AIREFINER")
if not logger.handlers:
    handler = logging.StreamHandler()
    fmt = logging.Formatter("[%(asctime)s] %(levelname)s: %(message)s")
    handler.setFormatter(fmt)
    logger.addHandler(handler)
logger.setLevel(logging.INFO)

# -----------------------------------
# âš™ï¸ è¨­å®šãƒ­ãƒ¼ãƒ‰
# -----------------------------------
def load_configs():
    load_dotenv(".env.txt")
    openai.api_key = os.getenv("OPENAI_API_KEY")

    with open("kotoha_config.json", "r", encoding="utf-8") as f:
        global_cfg = json.load(f)
    with open("config/modules/ai_refiner.json", "r", encoding="utf-8") as f:
        module_cfg = json.load(f)

    output_dir = global_cfg.get("OUTPUT_DIR", "./")
    return openai.api_key, output_dir, module_cfg

# -----------------------------------
# ğŸ§  AIã«ã‚ˆã‚‹è‡ªç„¶æ–‡æœ€é©åŒ–é–¢æ•°
# -----------------------------------
def refine_text(prompt, model="gpt-4o-mini", temperature=0.8):
    """
    OpenAI API ã‚’å‘¼ã³å‡ºã—ã¦è‡ªç„¶æ–‡ãƒªãƒ•ã‚¡ã‚¤ãƒ³ã‚’è¡Œã†ã€‚
    - ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼: é­…åŠ›ã¨ç°¡æ½”æ€§ã‚’å¼·åŒ–
    - ALT: SEOçš„ã«è‡ªç„¶ãªæ–‡è„ˆã‚’ç¶­æŒ
    """
    try:
        response = openai.ChatCompletion.create(
            model=model,
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯æ—¥æœ¬èªãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ã‚³ãƒ”ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=temperature,
            max_tokens=120
        )
        return response["choices"][0]["message"]["content"].strip()
    except Exception as e:
        logger.error(f"ğŸš« OpenAIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return prompt  # å®‰å…¨è¨­è¨ˆï¼šå…ƒæ–‡ã‚’è¿”ã™

# -----------------------------------
# ğŸš€ ãƒ¡ã‚¤ãƒ³å‡¦ç†
# -----------------------------------
def run_ai_refiner():
    api_key, output_dir, module_cfg = load_configs()
    if not api_key:
        logger.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ (.env.txt ã‚’ç¢ºèªã—ã¦ãã ã•ã„)")
        return

    # æœ€æ–°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    files = sorted(glob.glob(os.path.join(output_dir, "output_templates_*.csv")))
    if not files:
        logger.error("âŒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚template_composer.py ã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    latest_file = files[-1]
    logger.info(f"ğŸ“„ å…¥åŠ›ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: {latest_file}")

    df = pd.read_csv(latest_file, dtype=str).fillna("")

    # å„è¡Œå‡¦ç†
    refined_rows = []
    for idx, row in df.iterrows():
        name = row.get("å•†å“å", "")
        copy_raw = row.get("ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼", "")
        alt_cols = [c for c in df.columns if "ALT" in c]

        # ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼æœ€é©åŒ–
        copy_prompt = f"æ¬¡ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’è‡ªç„¶ã§é­…åŠ›çš„ãªæ—¥æœ¬èªã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã«æ•´ãˆã¦ãã ã•ã„ï¼ˆ30ã€œ60æ–‡å­—ï¼‰ï¼š\nã€Œ{copy_raw}ã€"
        refined_copy = refine_text(copy_prompt)

        # ALTæœ€é©åŒ–
        refined_alts = []
        for c in alt_cols:
            alt_prompt = f"æ¬¡ã®ALTæ–‡ã‚’SEOçš„ã«è‡ªç„¶ã§èª­ã¿ã‚„ã™ãæ•´ãˆã¦ãã ã•ã„ï¼ˆã€œ60æ–‡å­—ï¼‰ï¼š\nã€Œ{row[c]}ã€"
            refined_alts.append(refine_text(alt_prompt, temperature=0.6))

        row["ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼"] = refined_copy
        for i, c in enumerate(alt_cols):
            row[c] = refined_alts[i]

        refined_rows.append(row)

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = os.path.join(output_dir, f"output_final_{timestamp}.csv")
    pd.DataFrame(refined_rows).to_csv(output_file, encoding="utf-8-sig", index=False)

    logger.info(f"ğŸ’¾ æœ€çµ‚å‡ºåŠ›å®Œäº†: {output_file}")
    logger.info(f"âœ… ç”Ÿæˆä»¶æ•°: {len(refined_rows)} ä»¶")
    logger.info("ğŸŒ¸ KOTOHA ENGINE ãŒè·äººå‹ãƒ•ã‚§ãƒ¼ã‚ºã«åˆ°é”ã—ã¾ã—ãŸã€‚")

# -----------------------------------
# âœ… ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
# -----------------------------------
if __name__ == "__main__":
    logger.info("ğŸŒ¸ KOTOHA ENGINE ai_refiner èµ·å‹• â€” æ„Ÿæ€§ã§ç£¨ãè‡ªç„¶æ–‡ç”Ÿæˆå±¤")
    run_ai_refiner()
import atlas_autosave_core
