# -*- coding: utf-8 -*-
"""
Atlas Session Splitter v1.0
---------------------------------------
KOTOHA / Atlas ã®å·¨å¤§ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’3åˆ†å‰² (persona / dev / ops)
æ§‹é€ :
  config/atlas_session_cache.json â†’ å„ç¨®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆç”Ÿæˆ
  config/atlas_session_index.json ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç™»éŒ²
ç’°å¢ƒå¤‰æ•° (.env):
  ATLAS_SPLIT_CACHE, ATLAS_SNAPSHOT_DIR, ATLAS_MAX_SNAPSHOTS
"""

import os, json, time, shutil, glob
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

# =========================
# è¨­å®šã¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# =========================
BASE = Path("/Users/tsuyoshi/Desktop/python_lesson")
CFG_DIR = BASE / "config"
SESSION_PATH = CFG_DIR / "atlas_session_cache.json"
TIMELINE_PATH = CFG_DIR / "atlas_timeline.json"
INDEX_PATH = CFG_DIR / "atlas_session_index.json"

load_dotenv(BASE / ".env")

def getenv(key, default=""):
    v = os.getenv(key, "").strip()
    return v if v else default

def load_json(p: Path):
    try:
        with open(p, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return {}

def dump_json(p: Path, obj):
    p.parent.mkdir(parents=True, exist_ok=True)
    with open(p, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)

# =========================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯
# =========================
def pick_context_blocks(session_obj: dict):
    """Atlasã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ persona / dev / ops ã«åˆ†é›¢"""
    persona_keys = {"persona_engine", "kotoha", "values", "style", "ethos", "tone"}
    dev_keys     = {"current_model", "knowledge_loaded", "notes", "modules", "freeze", "router", "writer"}
    ops_keys     = {"phase", "files", "runs", "metrics", "snapshots"}

    persona, dev, ops = {}, {}, {}

    for k, v in session_obj.items():
        k_l = str(k).lower()
        if k in persona_keys or "persona" in k_l or "kotoha" in k_l:
            persona[k] = v
        elif k in dev_keys or any(s in k_l for s in ["writer","router","module","prompt","semantic","json","kb"]):
            dev[k] = v
        elif k in ops_keys or any(s in k_l for s in ["phase","run","stat","timeline","cache","atlas"]):
            ops[k] = v
        else:
            ops[k] = v

    return persona, dev, ops

# =========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# =========================
def main():
    split_on = getenv("ATLAS_SPLIT_CACHE", "OFF").upper() == "ON"
    snap_dir = Path(getenv("ATLAS_SNAPSHOT_DIR", str(CFG_DIR / "atlas_snapshots")))
    max_keep = int(getenv("ATLAS_MAX_SNAPSHOTS", "12") or "12")

    if not split_on:
        print("ğŸ”• ATLAS_SPLIT_CACHE=OFFï¼ˆä½•ã‚‚ã—ã¾ã›ã‚“ï¼‰")
        return

    session = load_json(SESSION_PATH)
    timeline = load_json(TIMELINE_PATH)
    persona, dev, ops = pick_context_blocks(session)

    stamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    outdir = snap_dir / stamp
    outdir.mkdir(parents=True, exist_ok=True)

    dump_json(outdir / "persona.json", persona)
    dump_json(outdir / "dev.json", dev)
    dump_json(outdir / "ops.json", ops)

    index = {
        "active_stamp": stamp,
        "paths": {
            "persona": str(outdir / "persona.json"),
            "dev": str(outdir / "dev.json"),
            "ops": str(outdir / "ops.json"),
        },
        "meta": {
            "snapshot_root": str(snap_dir),
            "max_keep": max_keep,
            "timeline_hint": timeline.get("summary", {}) if isinstance(timeline, dict) else {}
        }
    }
    dump_json(INDEX_PATH, index)

    # å¤ã„ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå‰Šé™¤
    snaps = sorted(glob.glob(str(snap_dir / "*")), reverse=True)
    for old in snaps[max_keep:]:
        try:
            shutil.rmtree(old)
        except Exception:
            pass

    print("âœ… Atlas åˆ†å‰²ã‚¹ãƒŠãƒƒãƒ—å®Œäº†")
    print(f"ğŸ“ æœ€æ–°ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆ: {outdir}")
    print(f"ğŸ§­ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹: {INDEX_PATH}")

if __name__ == "__main__":
    main()