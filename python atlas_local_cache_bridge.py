# -*- coding: utf-8 -*-
"""
atlas_local_cache_bridge.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Atlas â†” Python ãƒ­ãƒ¼ã‚«ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ»ãƒ–ãƒªãƒƒã‚¸ï¼ˆæ‹¡å¼µï¼‰
- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆãƒ¢ãƒ‡ãƒ«/é€²æ—/ãƒ­ã‚°ï¼‰ã«åŠ ãˆã€
  ãƒ»KOTOHAäººæ ¼ï¼ˆkotoha_persona.jsonï¼‰
  ãƒ»çŸ¥è¦‹ãƒãƒ©ãƒ³ã‚µãƒ¼æˆæœï¼ˆknowledge_fused_structured_v2_1.jsonï¼‰
  ã‚’è‡ªå‹•ãƒ­ãƒ¼ãƒ‰ï¼‹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã¸çµ±åˆã€‚
- TTLç®¡ç†ãƒ»ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆè¿½è¨˜ãƒ»ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆå¯¾å¿œã€‚
- ã©ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰ã‚‚ import ã—ã¦ä½¿ãˆã‚‹è»½é‡APIã€‚
"""

from __future__ import annotations
import os
import json
import time
import sys
import shutil
from dataclasses import dataclass, asdict
from typing import Any, Dict, Optional, List
from datetime import datetime

# ====== å›ºå®šãƒ‘ã‚¹ï¼ˆè¦ã¨ã—ã¦è¨˜æ†¶ãƒ»å…¨ã‚³ãƒ¼ãƒ‰ã§å…±é€šï¼‰======
BASE_DIR   = "/Users/tsuyoshi/Desktop/python_lesson"
CONFIG_DIR = os.path.join(BASE_DIR, "config")
OUT_DIR    = os.path.join(BASE_DIR, "output")
SEM_DIR    = os.path.join(OUT_DIR, "semantics")

CACHE_FILE = os.path.join(CONFIG_DIR, "atlas_session_cache.json")
CACHE_TTL_HOURS = 72

# KOTOHAäººæ ¼ï¼ˆç”Ÿæˆæ¸ˆï¼‰
PERSONA_FILE = os.path.join(CONFIG_DIR, "kotoha_persona.json")

# çŸ¥è¦‹ãƒãƒ©ãƒ³ã‚µãƒ¼æˆæœï¼ˆv2.1ã§ç”Ÿæˆï¼‰
FUSED_KNOWLEDGE_FILE = os.path.join(SEM_DIR, "knowledge_fused_structured_v2_1.json")

# å°†æ¥ã®æ‹¡å¼µã«å‚™ãˆã¦æ˜ç¤º
CSV_RAKUTEN = "/Users/tsuyoshi/Desktop/python_lesson/sauce/rakuten.csv"
CSV_YAHOO   = "/Users/tsuyoshi/Desktop/python_lesson/sauce/yahoo.csv"
FMT_RAKUTEN = "/Users/tsuyoshi/Desktop/python_lesson/sauce/Rakuten_Format.csv"
FMT_YAHOO   = "/Users/tsuyoshi/Desktop/python_lesson/sauce/YAHOO_Format.csv"


# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ======
def _ensure_dir(path: str):
    if not os.path.exists(path):
        os.makedirs(path)

def _now_ts() -> int:
    return int(time.time())

def _expired(ts: int, hours: int = CACHE_TTL_HOURS) -> bool:
    return (_now_ts() - int(ts)) > hours * 3600

def _safe_load_json(path: str) -> Optional[Any]:
    if not os.path.exists(path):
        return None
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def _atomic_write_json(path: str, data: Any):
    tmp = f"{path}.tmp"
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    shutil.move(tmp, path)


# ====== ãƒ‡ãƒ¼ã‚¿æ§‹é€  ======
@dataclass
class PersonaState:
    enabled: bool = True         # äººæ ¼ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ã†ã‹
    version: str = "KOTOHA_v1.0" # ä»»æ„ã®è¡¨ç¤ºç”¨
    payload: Dict[str, Any] = None  # kotoha_persona.json ã®ä¸­èº«

@dataclass
class KnowledgeState:
    fused_loaded: bool = False
    fused_payload: Dict[str, Any] = None
    sources: List[str] = None  # ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ§‹ç¯‰ã—ãŸã‹ã®ç—•è·¡

@dataclass
class SessionContext:
    phase: str = "INIT"
    current_model: str = ""        # ä¾‹: gpt-5-turbo
    openai_mode: str = "chat"      # chat/responses
    temperature: float = 1.0
    notes: str = ""
    events: List[Dict[str, Any]] = None

@dataclass
class AtlasCache:
    _timestamp: int
    _saved_at: str
    session: SessionContext
    persona: PersonaState
    knowledge: KnowledgeState


# ====== ãƒ­ãƒ¼ãƒ€ãƒ¼ ======
def _load_persona() -> PersonaState:
    data = _safe_load_json(PERSONA_FILE) or {}
    return PersonaState(
        enabled=True,
        version=data.get("version") or "KOTOHA_v1.0",
        payload=data
    )

def _load_knowledge() -> KnowledgeState:
    fused = _safe_load_json(FUSED_KNOWLEDGE_FILE) or {}
    loaded = bool(fused)
    sources = []
    if loaded:
        sources.append(os.path.basename(FUSED_KNOWLEDGE_FILE))
    return KnowledgeState(
        fused_loaded=loaded,
        fused_payload=fused if loaded else {},
        sources=sources
    )

def _new_cache(context_hint: Optional[Dict[str, Any]] = None) -> AtlasCache:
    # åˆæœŸã‚»ãƒƒã‚·ãƒ§ãƒ³
    sess = SessionContext(
        phase = (context_hint or {}).get("phase", "ALTç”Ÿæˆãƒ•ã‚§ãƒ¼ã‚º"),
        current_model = (context_hint or {}).get("current_model", os.getenv("OPENAI_MODEL", "")),
        openai_mode = os.getenv("OPENAI_MODE", "chat"),
        temperature = float(os.getenv("OPENAI_TEMPERATURE", "1.0")),
        notes = "åˆæœŸåŒ–",
        events = []
    )
    persona = _load_persona()
    knowledge = _load_knowledge()
    return AtlasCache(
        _timestamp=_now_ts(),
        _saved_at=datetime.now().isoformat(),
        session=sess,
        persona=persona,
        knowledge=knowledge
    )


# ====== ãƒ‘ãƒ–ãƒªãƒƒã‚¯API ======
def load_cache(auto_refresh: bool = True) -> AtlasCache:
    """
    ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’èª­ã¿è¾¼ã‚€ã€‚å­˜åœ¨ã—ãªã„/æœŸé™åˆ‡ã‚Œãªã‚‰æ–°è¦ç”Ÿæˆã€‚
    """
    _ensure_dir(CONFIG_DIR)
    data = _safe_load_json(CACHE_FILE)
    if not data or (auto_refresh and _expired(data.get("_timestamp", 0))):
        cache = _new_cache()
        save_cache(cache)
        print("ğŸ•’ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–ï¼ˆæ–°è¦ï¼‰")
        return cache

    try:
        # å¾©å…ƒ
        session = SessionContext(**(data.get("session") or {}))
        persona = PersonaState(**(data.get("persona") or {}))
        knowledge = KnowledgeState(**(data.get("knowledge") or {}))
        cache = AtlasCache(
            _timestamp=data.get("_timestamp", _now_ts()),
            _saved_at=data.get("_saved_at", datetime.now().isoformat()),
            session=session,
            persona=persona,
            knowledge=knowledge
        )
        print(f"âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­è¾¼: {CACHE_FILE}")
        return cache
    except Exception:
        # å£Šã‚Œã¦ã„ãŸã‚‰ä½œã‚Šç›´ã™
        cache = _new_cache()
        save_cache(cache)
        print("âš ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç ´æ â†’ å†ç”Ÿæˆ")
        return cache

def save_cache(cache: AtlasCache):
    payload = {
        "_timestamp": _now_ts(),
        "_saved_at": datetime.now().isoformat(),
        "session": asdict(cache.session),
        "persona": asdict(cache.persona),
        "knowledge": asdict(cache.knowledge),
    }
    _ensure_dir(CONFIG_DIR)
    _atomic_write_json(CACHE_FILE, payload)
    # ç‡ç›´ãªãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
    print(f"ğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜: {CACHE_FILE}")

def flush_cache():
    if os.path.exists(CACHE_FILE):
        os.remove(CACHE_FILE)
        print("ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤å®Œäº†")
    else:
        print("â„¹ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—")

def set_persona_enabled(cache: AtlasCache, enabled: bool):
    cache.persona.enabled = enabled
    save_cache(cache)

def update_session(cache: AtlasCache, **kwargs):
    """
    ä¾‹:
      update_session(cache, phase="ALTç”Ÿæˆ", current_model="gpt-5-turbo")
    """
    for k, v in kwargs.items():
        if hasattr(cache.session, k):
            setattr(cache.session, k, v)
    save_cache(cache)

def record_event(cache: AtlasCache, tag: str, detail: Dict[str, Any]):
    if cache.session.events is None:
        cache.session.events = []
    cache.session.events.append({
        "ts": datetime.now().isoformat(),
        "tag": tag,
        "detail": detail
    })
    # ç›´ã¡ã«ä¿å­˜ï¼ˆéšœå®³æ™‚ã‚‚è¿½è·¡ã§ãã‚‹ã‚ˆã†ã«ï¼‰
    save_cache(cache)

def snapshot_paths() -> Dict[str, str]:
    """ ä»–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒå‚ç…§ã§ãã‚‹åŸºç¤ãƒ‘ã‚¹ç¾¤ """
    return {
        "BASE_DIR": BASE_DIR,
        "CONFIG_DIR": CONFIG_DIR,
        "OUT_DIR": OUT_DIR,
        "SEM_DIR": SEM_DIR,
        "CACHE_FILE": CACHE_FILE,
        "PERSONA_FILE": PERSONA_FILE,
        "FUSED_KNOWLEDGE_FILE": FUSED_KNOWLEDGE_FILE,
        "CSV_RAKUTEN": CSV_RAKUTEN,
        "CSV_YAHOO": CSV_YAHOO,
        "FMT_RAKUTEN": FMT_RAKUTEN,
        "FMT_YAHOO": FMT_YAHOO,
    }


# ====== CLI ======
def _print(cache: AtlasCache):
    obj = {
        "_timestamp": cache._timestamp,
        "_saved_at": cache._saved_at,
        "session": asdict(cache.session),
        "persona": {
            "enabled": cache.persona.enabled,
            "version": cache.persona.version,
            "payload_keys": list((cache.persona.payload or {}).keys())
        },
        "knowledge": {
            "fused_loaded": cache.knowledge.fused_loaded,
            "source_files": cache.knowledge.sources or [],
            # ä¸­èº«ã¯å¤§ãã„ã®ã§éµã ã‘
            "payload_keys": list((cache.knowledge.fused_payload or {}).keys())
        }
    }
    print(json.dumps(obj, ensure_ascii=False, indent=2))

if __name__ == "__main__":
    # ä½¿ã„æ–¹:
    #   python atlas_local_cache_bridge.py           # èª­ã¿è¾¼ã¿ï¼ˆç„¡ã‘ã‚Œã°æ–°è¦ä½œæˆï¼‰
    #   python atlas_local_cache_bridge.py --flush   # å‰Šé™¤
    #   python atlas_local_cache_bridge.py --disable-persona / --enable-persona
    if "--flush" in sys.argv:
        flush_cache()
        sys.exit(0)

    cache = load_cache(auto_refresh=True)

    if "--disable-persona" in sys.argv:
        set_persona_enabled(cache, False)
        print("ğŸ”• äººæ ¼ã‚¨ãƒ³ã‚¸ãƒ³: OFF")
        sys.exit(0)
    if "--enable-persona" in sys.argv:
        set_persona_enabled(cache, True)
        print("ğŸ”” äººæ ¼ã‚¨ãƒ³ã‚¸ãƒ³: ON")
        sys.exit(0)

    _print(cache)
import atlas_autosave_core
