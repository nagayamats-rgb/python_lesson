import os
import json
import time
import logging
from datetime import datetime
from tqdm import tqdm
from dotenv import load_dotenv

# ==============================================
# ğŸŒ¸ KOTOHA ENGINE â€” Template Mapper v1.2 Smart Accessory Optimized
# ==============================================

logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(levelname)s: %(message)s')

load_dotenv()
OUTPUT_DIR = "./output/semantics"
INPUT_DIR = "./output"
os.makedirs(OUTPUT_DIR, exist_ok=True)

def find_latest_file(directory=INPUT_DIR, prefix="lexical_clusters_", ext=".json"):
    """æœ€æ–°ã® lexical_clusters ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º"""
    try:
        files = [f for f in os.listdir(directory) if f.startswith(prefix) and f.endswith(ext)]
        if not files:
            logging.error("âŒ lexical_clusters_*.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None
        files.sort(key=lambda f: os.path.getmtime(os.path.join(directory, f)), reverse=True)
        latest = os.path.join(directory, files[0])
        logging.info(f"ğŸ“„ æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨: {latest}")
        return latest
    except Exception as e:
        logging.error(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def load_templates():
    """æ¥­ç¨®ç‰¹åŒ–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆã‚¹ãƒãƒ›ã‚¢ã‚¯ã‚»ï¼‰ã‚’èª­ã¿è¾¼ã¿"""
    templates = {
        "specs": [
            "æœ€æ–°ã® {keyword} ã‚’æ¡ç”¨ã—ã€{feature} ã‚’å®Ÿç¾ã€‚",
            "{material} ç´ æã§é«˜è€ä¹…ãƒ»è»½é‡è¨­è¨ˆã€‚"
        ],
        "usability": [
            "æŒã¡é‹ã³ã‚„ã™ãã€{use_scene} ã«æœ€é©ã€‚",
            "{device} ã«ãƒ•ã‚£ãƒƒãƒˆã—ã€æ—¥å¸¸ä½¿ã„ã‚‚å¿«é©ã€‚"
        ],
        "differentiation": [
            "ä»–ç¤¾è£½å“ã«ã¯ãªã„ {unique_point} ãŒé­…åŠ›ã€‚",
            "å£ã‚³ãƒŸè©•ä¾¡ã®é«˜ã„ {highlight} ã‚’æ­è¼‰ã€‚"
        ],
        "emotion": [
            "æ¯æ—¥ã®ä½¿ç”¨ãŒã‚‚ã£ã¨æ¥½ã—ããªã‚‹ {emotion_word} ä½“é¨“ã€‚",
            "è¦‹ãŸç›®ã‚‚ã‚¹ãƒãƒ¼ãƒˆã«ã€ã‚ãªãŸã‚‰ã—ã•ã‚’å¼•ãç«‹ã¦ã¾ã™ã€‚"
        ]
    }
    logging.info("ğŸ“š ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼ˆSmart Accessory Optimizedï¼‰")
    return templates


def map_clusters_to_templates(clusters, templates):
    """ã‚¯ãƒ©ã‚¹ã‚¿èªå½™ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å‰²ã‚Šå½“ã¦"""
    mapped_data = []
    for c in tqdm(clusters, desc="ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿ãƒãƒƒãƒ”ãƒ³ã‚°é€²è¡Œä¸­", unit="cluster"):
        cid = c.get("cluster_id")
        terms = c.get("terms", [])
        keywords = terms[:5]  # ä¸Šä½5ä»¶ã‚’ä»£è¡¨èªå½™ã¨ã—ã¦ä½¿ç”¨

        mapped_entry = {
            "cluster_id": cid,
            "keywords": keywords,
            "templates": {
                "specs": templates["specs"],
                "usability": templates["usability"],
                "differentiation": templates["differentiation"],
                "emotion": templates["emotion"]
            }
        }
        mapped_data.append(mapped_entry)
    return mapped_data


def main():
    start_time = time.time()
    logging.info("ğŸŒ¸ KOTOHA ENGINE â€” Template Mapper èµ·å‹•")

    input_file = find_latest_file()
    if not input_file:
        return

    with open(input_file, "r", encoding="utf-8") as f:
        clusters = json.load(f)

    templates = load_templates()
    mapped = map_clusters_to_templates(clusters, templates)

    output_path = os.path.join(
        OUTPUT_DIR, f"structured_semantics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    )

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(mapped, f, ensure_ascii=False, indent=2)

    elapsed = time.time() - start_time
    print("\nâœ… å®Œäº†! Template Mapper å®Ÿè¡Œçµæœ:")
    print(f"ğŸ•’ å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’")
    print(f"ğŸ’¾ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    print(f"ğŸ§© ã‚¯ãƒ©ã‚¹ã‚¿æ§‹æ–‡æ•°: {len(mapped)}")


if __name__ == "__main__":
    main()
import atlas_autosave_core
