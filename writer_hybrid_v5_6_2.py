# -*- coding: utf-8 -*-
"""
KOTOHA ENGINE â€” Hybrid AI Writer v5.6.2
GPT-5å®‰å…¨ãƒ¢ãƒ¼ãƒ‰ï¼åˆ†å‰²ALTç”Ÿæˆï¼‹å†è©¦è¡Œãƒ»ãƒ­ã‚°å¼·åŒ–ç‰ˆ
"""

import os, csv, json, re
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

# ===============================
# ãƒ‘ã‚¹è¨­å®š
# ===============================
BASE_DIR = "/Users/tsuyoshi/Desktop/python_lesson"
INPUT_CSV = os.path.join(BASE_DIR, "input.csv")
SEM_DIR = os.path.join(BASE_DIR, "output/semantics")
OUT_DIR = os.path.join(BASE_DIR, "output/ai_writer")
os.makedirs(OUT_DIR, exist_ok=True)

load_dotenv(os.path.join(BASE_DIR, ".env"))
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
ENCODING_IN = "cp932"

# ===============================
# ä¸­é–“ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
# ===============================
PATH_LEXICAL = os.path.join(SEM_DIR, "lexical_clusters_20251030_223013.json")
PATH_MARKET  = os.path.join(SEM_DIR, "market_vocab_20251030_201906.json")
PATH_SEMANT  = os.path.join(SEM_DIR, "structured_semantics_20251030_224846.json")
PATH_PERSONA = os.path.join(SEM_DIR, "styled_persona_20251031_0031.json")
PATH_NORMAL  = os.path.join(SEM_DIR, "normalized_20251031_0039.json")
PATH_TEMPLATE = os.path.join(SEM_DIR, "template_composer.json")

# ===============================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
# ===============================
def sanitize(s: str):
    return re.sub(r"\s+", " ", s.replace("\u3000", " ").strip())

def load_json(p, d=None):
    try:
        with open(p, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return d or {}

def short(x):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè»½é‡åŒ–"""
    if isinstance(x, list):
        return x[:5]
    if isinstance(x, dict):
        return {k: x[k] for k in list(x.keys())[:5]}
    return x

def _parse_json_loose(text: str):
    """JSONãŒå£Šã‚Œã¦ã„ã¦ã‚‚ç·©ããƒ‘ãƒ¼ã‚¹"""
    import json, re
    if not text:
        return {}
    try:
        return json.loads(text)
    except:
        pass
    m = re.search(r'\{.*\}', text, re.DOTALL)
    if m:
        try:
            return json.loads(m.group(0))
        except:
            pass
    return {}

# ===============================
# GPTå‘¼ã³å‡ºã—ãƒ­ã‚¸ãƒƒã‚¯
# ===============================
def ai_generate(name, persona, lexical, market, sem, tmpl, norm):
    # forbidden_wordsã‚’å®‰å…¨å–å¾—
    if isinstance(norm, dict):
        forbidden_words = norm.get("forbidden_words", [])
    elif isinstance(norm, list):
        forbidden_words = norm
    else:
        forbidden_words = []

    sys_msg = "ã‚ãªãŸã¯æ—¥æœ¬èªECã‚³ãƒ”ãƒ¼ã®å°‚é–€å®¶ã§ã™ã€‚å¿…ãšJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚"

    base_prompt = f"""
å•†å“å: {name}

å‡ºåŠ›è¦ä»¶:
- 40ã€œ60æ–‡å­—ã®ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ã‚’ "copy" ã«
- 80ã€œ110æ–‡å­—ã®ALTæ–‡ã‚’10ä»¶ã€"alts" é…åˆ—ã«
- ç¦å‰‡èªã¯ä½¿ç”¨ã—ãªã„: {json.dumps(forbidden_words, ensure_ascii=False)}

è¿”å´ã¯æ¬¡ã®JSONã®ã¿ï¼ˆä»–ã®æ–‡å­—ã¯ç¦æ­¢ï¼‰:
{{
  "copy": "ã“ã“ã«ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼",
  "alts": ["ALT1","ALT2",...,"ALT10"]
}}
"""

    # -----------------------------
    # 1å›ç›®ï¼šcopy+ALT(1-10)
    # -----------------------------
    try:
        res1 = client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": base_prompt}
            ],
            response_format={"type": "json_object"},
            max_completion_tokens=600
        )
        raw1 = res1.choices[0].message.content or ""
        data1 = _parse_json_loose(raw1)
        copy = (data1.get("copy") or "").strip()
        alts1 = data1.get("alts") or []
    except Exception as e:
        copy, alts1, raw1 = "", [], f"ERROR:{e}"

    # å¤±æ•—ãƒ»ç©ºå¿œç­”æ™‚ã¯ãƒªãƒˆãƒ©ã‚¤
    if not copy or not alts1:
        retry_prompt = f"""
å•†å“å: {name}
JSONã®ã¿ã§è¿”ç­”:
{{"copy":"40-60æ–‡å­—","alts":["80-110æ–‡å­—ALTÃ—10"]}}
ç¦å‰‡èª: {json.dumps(forbidden_words, ensure_ascii=False)}
"""
        try:
            res1b = client.chat.completions.create(
                model="gpt-5",
                messages=[
                    {"role": "system", "content": sys_msg},
                    {"role": "user", "content": retry_prompt}
                ],
                response_format={"type": "json_object"},
                max_completion_tokens=550
            )
            raw1b = res1b.choices[0].message.content or ""
            data1b = _parse_json_loose(raw1b)
            copy = copy or (data1b.get("copy") or "").strip()
            alts1 = alts1 or (data1b.get("alts") or [])
        except:
            pass

    # -----------------------------
    # 2å›ç›®ï¼šALT(11-20)
    # -----------------------------
    alt_prompt = f"""
å•†å“å: {name}
å…ˆã»ã©ã¨é‡è¤‡ã—ãªã„ALTæ–‡ã‚’10ä»¶è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
JSONã®ã¿:
{{"alts":["...Ã—10"]}}
ç¦å‰‡èª: {json.dumps(forbidden_words, ensure_ascii=False)}
"""
    try:
        res2 = client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": sys_msg},
                {"role": "user", "content": alt_prompt}
            ],
            response_format={"type": "json_object"},
            max_completion_tokens=450
        )
        raw2 = res2.choices[0].message.content or ""
        data2 = _parse_json_loose(raw2)
        alts2 = data2.get("alts") or []
    except Exception:
        alts2 = []

    alts = (alts1 + alts2)[:20]

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not copy:
        copy = "ä¸Šè³ªãªä½¿ã„å¿ƒåœ°ã‚’è¿½æ±‚ã—ãŸäººæ°—ã®å®šç•ªã‚¢ã‚¤ãƒ†ãƒ "
    while len(alts) < 20:
        alts.append("")

    return copy, alts

# ===============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===============================
def main():
    print("ğŸŒ¸ Hybrid AI Writer v5.6.2 å®Ÿè¡Œé–‹å§‹ï¼ˆå®‰å…¨ãƒ¢ãƒ¼ãƒ‰ï¼åˆ†å‰²ALTç”Ÿæˆï¼‹å†è©¦è¡Œï¼‰")

    cfg = {
        "lex": load_json(PATH_LEXICAL),
        "market": load_json(PATH_MARKET),
        "sem": load_json(PATH_SEMANT),
        "persona": load_json(PATH_PERSONA),
        "tmpl": load_json(PATH_TEMPLATE),
        "norm": load_json(PATH_NORMAL)
    }

    # --- CSVèª­è¾¼ ---
    with open(INPUT_CSV, "r", encoding=ENCODING_IN) as f:
        rows = list(csv.reader(f))
    header = rows[0]
    name_idx = header.index("å•†å“å")
    names = [sanitize(r[name_idx]) for r in rows[1:] if len(r) > name_idx and sanitize(r[name_idx])]
    uniq = list(dict.fromkeys(names))
    print(f"âœ… å•†å“åæŠ½å‡º: {len(names)}ä»¶ â†’ ä¸€æ„åŒ–å¾Œ {len(uniq)}ä»¶")

    results = []
    csv_rows = [["å•†å“å", "ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼"] + [f"å•†å“ç”»åƒåï¼ˆALTï¼‰{i}" for i in range(1, 21)]]

    for nm in uniq:
        print(f"ğŸ§  ç”Ÿæˆä¸­: {nm[:30]}...")
        copy, alts = ai_generate(nm, cfg["persona"], cfg["lex"], cfg["market"], cfg["sem"], cfg["tmpl"], cfg["norm"])
        print(f"   â”œ copy:{len(copy)}å­— / alts:{sum(1 for a in alts if a)}ä»¶ ä¾‹:{(alts[0] or '')[:25]}â€¦")
        results.append({"product_name": nm, "copy": copy, "alts": alts})
        csv_rows.append([nm, copy] + alts)

    now = datetime.now().strftime("%Y%m%d_%H%M")
    jpath = os.path.join(OUT_DIR, f"hybrid_writer_full_{now}.json")
    cpath = os.path.join(OUT_DIR, f"hybrid_writer_preview_{now}.csv")

    with open(jpath, "w", encoding="utf-8") as f:
        json.dump({"items": results}, f, ensure_ascii=False, indent=2)
    with open(cpath, "w", encoding="utf-8-sig", newline="") as f:
        csv.writer(f).writerows(csv_rows)

    print(f"ğŸ’¾ å‡ºåŠ›å®Œäº†: {jpath}")
    print(f"ğŸ§¾ ç›®è¦–ç”¨CSV: {cpath}")
    print(f"ğŸ“Š ä»¶æ•°: {len(results)}ï¼ˆå…¨ä»¶AIç”Ÿæˆï¼ALT20ä»¶çµ±åˆï¼‰")

# ===============================
if __name__ == "__main__":
    main()
import atlas_autosave_core
