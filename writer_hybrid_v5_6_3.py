# -*- coding: utf-8 -*-
"""
KOTOHA ENGINE â€” Hybrid AI Writer v5.6.3
è‡ªç„¶æ–‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ»æŸ”è»Ÿå‡ºåŠ›ãƒ¢ãƒ¼ãƒ‰ï¼ˆGPT-5å¯¾å¿œï¼‰
"""

import os, csv, json, re
from datetime import datetime
from dotenv import load_dotenv
from openai import OpenAI

BASE_DIR = "/Users/tsuyoshi/Desktop/python_lesson"
INPUT_CSV = os.path.join(BASE_DIR, "input.csv")
SEM_DIR = os.path.join(BASE_DIR, "output/semantics")
OUT_DIR = os.path.join(BASE_DIR, "output/ai_writer")
os.makedirs(OUT_DIR, exist_ok=True)

load_dotenv(os.path.join(BASE_DIR, ".env"))
client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
ENCODING_IN = "cp932"

PATH_LEXICAL = os.path.join(SEM_DIR, "lexical_clusters_20251030_223013.json")
PATH_MARKET  = os.path.join(SEM_DIR, "market_vocab_20251030_201906.json")
PATH_SEMANT  = os.path.join(SEM_DIR, "structured_semantics_20251030_224846.json")
PATH_PERSONA = os.path.join(SEM_DIR, "styled_persona_20251031_0031.json")
PATH_NORMAL  = os.path.join(SEM_DIR, "normalized_20251031_0039.json")

def sanitize(s):
    return re.sub(r"\s+", " ", s.replace("\u3000", " ").strip())

def load_json(p):
    try:
        with open(p, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return {}

def extract_copy_and_alts(text):
    """copyã¨ALTã‚’æŸ”è»ŸæŠ½å‡º"""
    text = text.replace("ï¼š", ":").replace("ãƒ»", " ")
    copy_match = re.search(r"copy[:ï¼š]\s*(.+)", text, re.IGNORECASE)
    copy = copy_match.group(1).strip() if copy_match else ""
    # ALTæŠ½å‡ºï¼ˆç•ªå·ä»˜ããƒ»ç®‡æ¡æ›¸ãå¯¾å¿œï¼‰
    alts = re.findall(r"ALT\d*[:ï¼š]?\s*(.+)", text)
    if not alts:
        alts = re.findall(r"[-ãƒ»]\s*(.{20,120})", text)
    alts = [a.strip() for a in alts if len(a.strip()) > 20]
    return copy[:60], alts[:20]

def ai_generate(name, forbidden):
    prompt = f"""
ã‚ãªãŸã¯ECã‚µã‚¤ãƒˆã®æ—¥æœ¬èªã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®å•†å“ã«ã¤ã„ã¦ã€
é­…åŠ›çš„ã§SEOçš„ã«ã‚‚åŠ¹æœçš„ãªã‚³ãƒ”ãƒ¼ã¨ALTèª¬æ˜æ–‡ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€æ¡ä»¶ã€‘
ãƒ»ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼ï¼š40ã€œ60æ–‡å­—ç¨‹åº¦ã€æ—¥æœ¬èªã§è‡ªç„¶ã§å¿ƒã‚’æƒ¹ãè¡¨ç¾ã€‚
ãƒ»ALTèª¬æ˜æ–‡ï¼š80ã€œ110æ–‡å­—ç¨‹åº¦ã‚’20å€‹ã€‚å¤šæ§˜ã§é‡è¤‡ã—ãªã„å†…å®¹ã«ã€‚
ãƒ»ç¦æ­¢èªï¼š{", ".join(forbidden)}

ã€å‡ºåŠ›ä¾‹ã€‘
copy: å„ªã‚ŒãŸæ”¾ç†±æ€§ã§æ€¥é€Ÿå……é›»ã‚’å®Ÿç¾ã™ã‚‹ã‚¹ãƒãƒ¼ãƒˆå……é›»å™¨
ALT1: ã‚·ãƒ³ãƒ—ãƒ«ã§ã‚¹ã‚¿ã‚¤ãƒªãƒƒã‚·ãƒ¥ãªãƒ‡ã‚¶ã‚¤ãƒ³ã®ãƒã‚°ã‚»ãƒ¼ãƒ•å¯¾å¿œå……é›»å™¨ã§ã™...
ALT2: é«˜é€Ÿã‹ã¤å®‰å®šã—ãŸå……é›»ã‚’å®Ÿç¾ã—ã€æ—¥å¸¸ä½¿ã„ã«æœ€é©ãªå……é›»ã‚¹ã‚¿ãƒ³ãƒ‰...
â€¦
å•†å“å: {name}
"""

    try:
        res = client.chat.completions.create(
            model="gpt-5",
            messages=[{"role":"system","content":"ã‚ãªãŸã¯æ—¥æœ¬èªECã‚³ãƒ”ãƒ¼å°‚é–€å®¶ã§ã™ã€‚"},
                      {"role":"user","content":prompt}],
            max_completion_tokens=900
        )
        raw = res.choices[0].message.content or ""
        copy, alts = extract_copy_and_alts(raw)
    except Exception as e:
        print(f"âš ï¸ Error: {e}")
        copy, alts = "", []

    if not copy:
        copy = "ä¸Šè³ªãªä½¿ã„å¿ƒåœ°ã‚’è¿½æ±‚ã—ãŸäººæ°—ã®å®šç•ªã‚¢ã‚¤ãƒ†ãƒ "
    while len(alts) < 20:
        alts.append("")
    return copy, alts

def main():
    print("ğŸŒ¸ Hybrid AI Writer v5.6.3 å®Ÿè¡Œé–‹å§‹ï¼ˆè‡ªç„¶æ–‡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰")

    norm = load_json(PATH_NORMAL)
    forbidden = []
    if isinstance(norm, dict):
        forbidden = norm.get("forbidden_words", [])
    elif isinstance(norm, list):
        forbidden = norm

    with open(INPUT_CSV, "r", encoding=ENCODING_IN) as f:
        rows = list(csv.reader(f))
    header = rows[0]
    name_idx = header.index("å•†å“å")
    names = [sanitize(r[name_idx]) for r in rows[1:] if len(r) > name_idx and sanitize(r[name_idx])]
    uniq = list(dict.fromkeys(names))
    print(f"âœ… å•†å“åæŠ½å‡º: {len(names)}ä»¶ â†’ ä¸€æ„åŒ–å¾Œ {len(uniq)}ä»¶")

    results = []
    csv_rows = [["å•†å“å", "ã‚­ãƒ£ãƒƒãƒã‚³ãƒ”ãƒ¼"] + [f"å•†å“ç”»åƒåï¼ˆALTï¼‰{i}" for i in range(1, 21)]]

    for nm in uniq:
        print(f"ğŸ§  ç”Ÿæˆä¸­: {nm[:30]}...")
        copy, alts = ai_generate(nm, forbidden)
        print(f"   â”œ copy:{len(copy)}å­— / alts:{sum(1 for a in alts if a)}ä»¶ ä¾‹:{(alts[0] or '')[:25]}â€¦")
        results.append({"product_name": nm, "copy": copy, "alts": alts})
        csv_rows.append([nm, copy] + alts)

    now = datetime.now().strftime("%Y%m%d_%H%M")
    jpath = os.path.join(OUT_DIR, f"hybrid_writer_full_{now}.json")
    cpath = os.path.join(OUT_DIR, f"hybrid_writer_preview_{now}.csv")

    with open(jpath, "w", encoding="utf-8") as f:
        json.dump({"items": results}, f, ensure_ascii=False, indent=2)
    with open(cpath, "w", encoding="utf-8-sig", newline="") as f:
        csv.writer(f).writerows(csv_rows)

    print(f"ğŸ’¾ å‡ºåŠ›å®Œäº†: {jpath}")
    print(f"ğŸ§¾ ç›®è¦–ç”¨CSV: {cpath}")
    print(f"ğŸ“Š ä»¶æ•°: {len(results)}ï¼ˆå…¨ä»¶AIç”Ÿæˆï¼ALT20ä»¶çµ±åˆï¼‰")

if __name__ == "__main__":
    main()
import atlas_autosave_core
