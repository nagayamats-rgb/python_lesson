import csv, json, re, os, time
from datetime import datetime
from tqdm import tqdm
from openai import OpenAI
from dotenv import load_dotenv

# --- ç’°å¢ƒå¤‰æ•°ãƒ­ãƒ¼ãƒ‰ ---
load_dotenv()

# --- å›ºå®šè¨­å®š ---
INPUT_FILE = "rakuten.csv"
OUTPUT_DIR = "./output/ai_writer"
MODEL = "gpt-4o-mini"
MAX_TOKENS = 1000
ALT_COUNT = 20

# --- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ---
client = OpenAI()

# --- ç¦å‰‡èªãƒ»åŸºæœ¬æŒ‡é‡ ---
FORBIDDEN_WORDS = ["ç«¶åˆ", "ä»–ç¤¾", "å„ªä½æ€§", "å†™çœŸ", "ç”»åƒ", "ã‚¯ãƒªãƒƒã‚¯", "ã“ã¡ã‚‰"]
STRUCTURE_HINT = (
    "è‡ªç„¶ãªæ—¥æœ¬èªã§1æ–‡80ã€œ130æ–‡å­—ç¨‹åº¦ã€‚"
    "æ§‹æˆãƒ’ãƒ³ãƒˆï¼šã€å•†å“ã‚¹ãƒšãƒƒã‚¯â†’ã‚³ã‚¢ã‚³ãƒ³ãƒ”ã‚¿ãƒ³ã‚¹â†’ã©ã‚“ãªäººâ†’ã©ã‚“ãªã‚·ãƒ¼ãƒ³â†’ãƒ™ãƒãƒ•ã‚£ãƒƒãƒˆã€ã‚’è‡ªç„¶ã«å«ã‚ã¦ãã ã•ã„ã€‚"
    "ç”»åƒæå†™ã‚„ã‚¯ãƒªãƒƒã‚¯èª˜å°ã¯ç¦æ­¢ã€‚å¥èª­ç‚¹ãƒ»åŠ©è©ã§è‡ªç„¶ã«åˆ‡ã‚Œã‚‹æ–‡ä½“ã€‚"
)

def refine_text(text: str) -> str:
    text = re.sub(r"\s+", " ", text.strip())
    text = re.sub(r"ã€‚{2,}", "ã€‚", text)
    if len(text) > 120:
        sentences = text.split("ã€‚")
        result, total = [], 0
        for s in sentences:
            if not s:
                continue
            if total + len(s) + 1 <= 110:
                result.append(s)
                total += len(s) + 1
            else:
                break
        text = "ã€‚".join(result) + "ã€‚"
    return text

def parse_json_response(raw: str) -> list:
    """AIå¿œç­”ã‚’æŸ”è»Ÿã«ãƒ‘ãƒ¼ã‚¹"""
    try:
        return json.loads(raw)
    except Exception:
        match = re.search(r"\[.*\]", raw, re.S)
        if match:
            try:
                return json.loads(match.group(0))
            except Exception:
                pass
        match = re.search(r"\{.*\}", raw, re.S)
        if match:
            try:
                d = json.loads(match.group(0))
                if isinstance(d, dict):
                    return list(d.values())[0]
            except Exception:
                pass
    return []

def ai_generate_alt(product_name: str) -> list[str]:
    """1å•†å“ã«ã¤ãALT20ä»¶ã‚’ç”Ÿæˆ"""
    prompt = (
        f"ä»¥ä¸‹ã®å•†å“ã«ã¤ã„ã¦ã€SEOæœ€é©åŒ–ã•ã‚ŒãŸALTãƒ†ã‚­ã‚¹ãƒˆã‚’{ALT_COUNT}ä»¶ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚\n"
        f"å„ALTã¯å…¨è§’100ã€œ130æ–‡å­—ã§è‡ªç„¶ãªæ—¥æœ¬èªã«ã—ã¦ãã ã•ã„ã€‚\n"
        f"ç¦æ­¢èª: {', '.join(FORBIDDEN_WORDS)}\n"
        f"{STRUCTURE_HINT}\n"
        f"å•†å“å: {product_name}\n\n"
        "å‡ºåŠ›å½¢å¼: JSONé…åˆ—ï¼ˆä¾‹: [\"ALT1\", \"ALT2\", ...]ï¼‰"
    )

    for attempt in range(3):
        try:
            res = client.chat.completions.create(
                model=MODEL,
                messages=[{"role": "user", "content": prompt}],
                max_completion_tokens=MAX_TOKENS,
                temperature=1.0,
                response_format={"type": "json_object"},  # âœ… æ­£å¼æŒ‡å®š
            )
            data = res.choices[0].message.content
            parsed = parse_json_response(data)
            cleaned = [refine_text(a) for a in parsed if isinstance(a, str)]
            if len(cleaned) >= ALT_COUNT // 2:
                return cleaned[:ALT_COUNT]
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆã‚¨ãƒ©ãƒ¼({attempt+1}/3): {e}")
            time.sleep(3)
    return [""] * ALT_COUNT

def main():
    print("ğŸŒ¸ writer_splitter_perfect_v3.3_altfix_utf8_final å®Ÿè¡Œé–‹å§‹ï¼ˆå®‰å®šç‰ˆï¼‰")
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    with open(INPUT_FILE, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        products = [r["å•†å“å"] for r in reader if r.get("å•†å“å")]

    print(f"âœ… å•†å“åæŠ½å‡º: {len(products)}ä»¶ï¼ˆé‡è¤‡é™¤å»æ¸ˆï¼‰")
    results = []

    for nm in tqdm(products, desc="ğŸ§  ALTç”Ÿæˆä¸­"):
        alts = ai_generate_alt(nm)
        results.append({"å•†å“å": nm, **{f"ALT{i+1}": alts[i] if i < len(alts) else "" for i in range(ALT_COUNT)}})

    ts = datetime.now().strftime("%Y%m%d_%H%M")
    out_csv = os.path.join(OUTPUT_DIR, f"alt_text_{ts}.csv")
    out_json = os.path.join(OUTPUT_DIR, f"alt_text_{ts}.jsonl")

    with open(out_csv, "w", newline="", encoding="utf-8-sig") as f:
        fieldnames = ["å•†å“å"] + [f"ALT{i+1}" for i in range(ALT_COUNT)]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(results)

    with open(out_json, "w", encoding="utf-8") as f:
        for r in results:
            f.write(json.dumps(r, ensure_ascii=False) + "\n")

    print(f"âœ… å‡ºåŠ›å®Œäº†: {out_csv}\nâœ… ãƒ­ã‚°: {out_json}\nğŸŒ¸ å…¨ALTç”Ÿæˆçµ‚äº†ï¼ˆUTF-8ï¼å†è©¦è¡Œä¿è­·ä»˜ï¼‰")

if __name__ == "__main__":
    main()
import atlas_autosave_core
