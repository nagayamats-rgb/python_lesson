# -*- coding: utf-8 -*-
"""
writer_splitter_perfect_v3_5_unified_core.py
=========================================================
çµ±åˆãƒ©ã‚¤ã‚¿ãƒ¼ï¼ˆè¦ãƒ»KOTOHA Frameworkï¼‰

- æ¥½å¤©ãƒ»Yahooãƒ»ALTï¼ˆæ¥½å¤©å°‚ç”¨ï¼‰ã‚’å…¨ä»¶AIç”Ÿæˆ
- ãƒ­ãƒ¼ã‚«ãƒ«çŸ¥è¦‹ï¼ˆ/output/semantics/ï¼‰ã‚’è¦ç´„ã—AIã«æ¸¡ã™
- ç¦å‰‡èªãƒ»é•·ã•ãƒ»å¥ç‚¹è£œå®Œãªã©çµ±ä¸€ãƒ«ãƒ¼ãƒ«ã§æ•´å½¢
- GPT-4oï¼ˆ.env å›ºå®šï¼‰ã‚’åˆ©ç”¨
=========================================================

ã€è¦ï¼ˆã‹ã‚“ãªã‚ï¼‰æ§‹é€ ç†å¿µã€‘
---------------------------------------------------------
è¦ã¨ã¯ã€AIç”Ÿæˆãƒ»ãƒ­ãƒ¼ã‚«ãƒ«çŸ¥è¦‹ãƒ»æ•´å½¢ãƒ»ç¦å‰‡ãƒ»å‡ºåŠ›çµ±åˆã®çµç¯€ç‚¹ã§ã‚ã‚‹ã€‚

1. AIçŸ¥è¦‹æ´»ç”¨ï¼š/output/semantics/ é…ä¸‹ã® JSON ç¾¤ã‚’è‡ªå‹•é›†ç´„ã—ã€å•†å“åˆ¥ã«è¦ç´„ã€‚
2. å®‰å®šç”Ÿæˆæ§‹æ–‡ï¼šGPT å¿œç­”ã‚’ JSON æ§‹é€ ã§å—ã‘ã€å®‰å…¨ãƒ‘ãƒ¼ã‚¹ã¨å†è©¦è¡Œã‚’å‚™ãˆã‚‹ã€‚
3. æ•´å½¢ãƒ«ãƒ¼ãƒ«çµ±åˆï¼šç¦å‰‡èªãƒ»æ–‡å­—é•·ãƒ»å¥ç‚¹è£œå®Œãƒ»èªå°¾è‡ªç„¶åŒ–ã‚’å…¨å‡¦ç†ã«é©ç”¨ã€‚
4. å‡ºåŠ›çµ±åˆï¼šæ¥½å¤©ãƒ»Yahooãƒ»ALTï¼ˆæ¥½å¤©å°‚ç”¨ï¼‰ã‚’åŒä¸€ãƒ—ãƒ­ã‚»ã‚¹ã§åŒæ™‚ç”Ÿæˆã€‚

æœ¬ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å¿ƒè‡“éƒ¨ã§ã‚ã‚Šã€å¤‰æ›´æ™‚ã¯å†å¯©æŸ»ã®ä¸Šã§å‡çµè§£é™¤ã™ã‚‹ã€‚
=========================================================
"""

import os
import re
import csv
import json
import glob
import time
from dotenv import load_dotenv
from collections import defaultdict
from openai import OpenAI

try:
    from tqdm.auto import tqdm
except Exception:
    def tqdm(x, **k): return x


# =====================================================
# 0. ç’°å¢ƒåˆæœŸåŒ–
# =====================================================
def init_env_and_client():
    load_dotenv(override=True)
    api_key = os.getenv("OPENAI_API_KEY", "").strip()
    if not api_key:
        raise SystemExit("âŒ OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    client = OpenAI(api_key=api_key)
    model = "gpt-4o"
    return client, model


# =====================================================
# 1. å®šæ•°ãƒ»ç¦å‰‡èª
# =====================================================
BASE_FORBIDDEN = [
    "ç”»åƒ", "å†™çœŸ", "è¦‹ãŸç›®", "ä¸Šã®ç”»åƒ", "ä¸‹ã®å†™çœŸ", "å½“åº—", "å½“ç¤¾",
    "ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ã‚¯ãƒªãƒƒã‚¯", "ã“ã¡ã‚‰", "ãƒªãƒ³ã‚¯", "ãƒšãƒ¼ã‚¸",
    "ã‚«ãƒ¼ãƒˆ", "è³¼å…¥ã¯ã“ã¡ã‚‰", "é€æ–™ç„¡æ–™ï¼ˆç¢ºç´„ï¼‰", "è¿”é‡‘ä¿è¨¼", "ç«¶åˆ", "å„ªä½æ€§",
    "No.1", "ãƒŠãƒ³ãƒãƒ¼ãƒ¯ãƒ³", "æœ€å®‰", "æ¥­ç•Œæœ€é«˜", "æœ€å¼·"
]

# Yahooå°‚ç”¨ã®è²©ä¿ƒãƒ»èª˜å°èªï¼ˆALTã§ã¯ç¦æ­¢ï¼‰
ALT_FORBIDDEN_EXT = [
    "é€æ–™ç„¡æ–™", "ã‚»ãƒ¼ãƒ«", "æœŸé–“é™å®š", "ãƒã‚¤ãƒ³ãƒˆ", "ã‚¯ãƒ¼ãƒãƒ³", "ãŠè²·ã„å¾—",
    "å‰²å¼•", "ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³", "ã”æ³¨æ–‡", "æ—©ã„è€…å‹ã¡", "åœ¨åº«é™ã‚Š",
    "ãƒ¬ãƒ“ãƒ¥ãƒ¼æŠ•ç¨¿", "ã‚·ãƒ§ãƒƒãƒ—", "ãŠæ°—ã«å…¥ã‚Š", "ä»Šã™ã", "ç‰¹åˆ¥ä¾¡æ ¼", "æ•°é‡é™å®š"
]

FORBIDDEN_ALL = list({*BASE_FORBIDDEN, *ALT_FORBIDDEN_EXT})


# =====================================================
# 2. çŸ¥è¦‹çµ±åˆ
# =====================================================
SEMANTICS_DIR = "./output/semantics"

def safe_load_json(path):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def summarize_knowledge():
    if not os.path.isdir(SEMANTICS_DIR):
        return "çŸ¥è¦‹: ä¸»ãªç”¨é€”ãƒ»å¯¾è±¡ãƒ»ç‰¹å¾´ãƒ»ã‚¹ãƒšãƒƒã‚¯ãƒ»é–¢é€£èªã‚’è‡ªç„¶ã«å«ã‚ã¦ãã ã•ã„ã€‚", []

    files = glob.glob(os.path.join(SEMANTICS_DIR, "*.json"))
    clusters, market, semantics, tone, template, forb = [], [], [], [], [], []

    for p in files:
        data = safe_load_json(p)
        if not data: continue
        name = os.path.basename(p).lower()

        if "cluster" in name:
            if isinstance(data, dict):
                arr = data.get("clusters", [])
                for c in arr:
                    if isinstance(c, dict):
                        terms = c.get("terms", [])
                        clusters.extend([t for t in terms if isinstance(t, str)])
        elif "market" in name:
            if isinstance(data, list):
                for v in data:
                    if isinstance(v, dict) and "vocabulary" in v:
                        market.append(v["vocabulary"])
                    elif isinstance(v, str):
                        market.append(v)
        elif "semantic" in name:
            if isinstance(data, dict):
                for k in ["concepts", "scenes", "targets"]:
                    semantics.extend(data.get(k, []))
        elif "persona" in name:
            if isinstance(data, dict):
                tone.append(json.dumps(data))
        elif "template" in name:
            if isinstance(data, dict):
                template.extend(data.get("hints", []))
        elif "forbid" in name or "normalized" in name:
            if isinstance(data, dict):
                forb.extend(data.get("forbidden_words", []))

    text = "çŸ¥è¦‹: " + "ã€".join(set(clusters + market + semantics))[:300]
    return text, list({*FORBIDDEN_ALL, *forb})


# =====================================================
# 3. å…¥åŠ›ãƒ­ãƒ¼ãƒ‰
# =====================================================
def load_products(csv_path="./rakuten.csv"):
    if not os.path.exists(csv_path):
        raise SystemExit(f"å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_path}")
    products = []
    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            name = (row.get("å•†å“å") or "").strip()
            if name:
                products.append(name)
    seen, uniq = set(), []
    for p in products:
        if p not in seen:
            uniq.append(p)
            seen.add(p)
    return uniq


# =====================================================
# 4. AIå‘¼ã³å‡ºã—
# =====================================================
def call_openai_json(client, model, messages, retry=3, wait=5):
    last_err = None
    for _ in range(retry):
        try:
            res = client.chat.completions.create(
                model=model,
                messages=messages,
                max_completion_tokens=1200,
                response_format={"type": "json_object"},
                temperature=1,
            )
            return json.loads(res.choices[0].message.content)
        except Exception as e:
            last_err = e
            time.sleep(wait)
    raise RuntimeError(f"OpenAIå‘¼ã³å‡ºã—å¤±æ•—: {last_err}")


# =====================================================
# 5. æ•´å½¢ãƒ«ãƒ¼ãƒ«
# =====================================================
def refine_text(text):
    if not text:
        return ""
    t = re.sub(r"\s+", " ", text.strip())
    if not t.endswith("ã€‚"):
        t += "ã€‚"
    for ng in FORBIDDEN_ALL:
        t = t.replace(ng, "")
    return t[:110].strip()


# =====================================================
# 6. ãƒ¡ã‚¤ãƒ³
# =====================================================
def main():
    print("ğŸŒ¸ writer_splitter_perfect_v3_5_unified_core å®Ÿè¡Œé–‹å§‹ï¼ˆè¦ï¼æ¥½å¤©ALTå°‚ç”¨ï¼‰")
    client, model = init_env_and_client()
    knowledge, forbidden_local = summarize_knowledge()

    products = load_products()
    print(f"âœ… å•†å“åæŠ½å‡º: {len(products)}ä»¶ï¼ˆé‡è¤‡é™¤å»æ¸ˆï¼‰")

    out_path = "./output/ai_writer/rakuten_alt_core.csv"
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    with open(out_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["å•†å“å"] + [f"ALT_{i+1}" for i in range(20)])

        for p in tqdm(products, desc="ğŸ§  å•†å“åˆ¥AIç”Ÿæˆä¸­", total=len(products)):
            sys_msg = {
                "role": "system",
                "content": (
                    "ã‚ãªãŸã¯æ—¥æœ¬èªã®ãƒ—ãƒ­ã‚³ãƒ”ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚"
                    "æ¥½å¤©å¸‚å ´ã®å•†å“ç”»åƒALTã‚’ç”Ÿæˆã—ã¾ã™ã€‚"
                    "è‡ªç„¶ãªæ—¥æœ¬èªã§ã€1ã€œ2æ–‡ã€å…¨è§’80ã€œ110æ–‡å­—ã«åã‚ã€å¥ç‚¹ã§çµ‚ãˆã‚‹ã“ã¨ã€‚"
                    "ç”»åƒã‚„å†™çœŸãªã©ã®æå†™èªã€è²©ä¿ƒèªï¼ˆé€æ–™ç„¡æ–™ã€ã‚»ãƒ¼ãƒ«ã€ä»Šã™ã ç­‰ï¼‰ã¯ç¦æ­¢ã§ã™ã€‚"
                )
            }
            user_msg = {
                "role": "user",
                "content": (
                    f"å•†å“å: {p}\n{knowledge}\n"
                    "20ä»¶ã®è‡ªç„¶æ–‡ALTã‚’JSONå½¢å¼ã§ç”Ÿæˆã—ã€ã‚­ãƒ¼ã¯ alt1ã€œalt20 ã«ã—ã¦ãã ã•ã„ã€‚"
                )
            }

            try:
                data = call_openai_json(client, model, [sys_msg, user_msg])
                alts = [refine_text(data.get(f"alt{i+1}", "")) for i in range(20)]
            except Exception as e:
                alts = [f"{p} ã¯æ¯æ—¥ã®ç”Ÿæ´»ã‚’å¿«é©ã«ã™ã‚‹å®Ÿç”¨çš„ãªãƒ‡ã‚¶ã‚¤ãƒ³ã§ã™ã€‚"] * 20
            writer.writerow([p] + alts)
            time.sleep(0.2)

    print(f"âœ… å‡ºåŠ›å®Œäº†: {out_path}")
    print("ğŸ”’ å‡çµãƒãƒ¼ã‚¸ãƒ§ãƒ³ï¼šè¦ï¼ˆã‹ã‚“ãªã‚ï¼‰æ­£å¼å®Ÿè£…ãƒ»æ¥½å¤©ALTå°‚ç”¨æ§‹æˆ")


if __name__ == "__main__":
    main()
import atlas_autosave_core
